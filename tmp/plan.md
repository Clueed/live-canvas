# Goal

The primary goal of `performComplexEditOperation` is to serve as a specialized AI function (or 'tool') designed to be invoked by a higher-level LLM agent. When called, it receives a specific editing instruction (the `prompt`) generated by the calling agent. Its responsibility is to act as an orchestrator, interpreting this instruction and translating it into a sequence of actions using available low-level editor functions. It leverages its own instance of an AI model (Gemini) to understand the instruction, break down the task into executable steps via function calls, manage the interaction with the model, and ultimately execute the required edits within the editor on behalf of the calling agent.

# Incremental Implementation Plan

This plan follows an incremental approach. Each step builds upon the previous one, introducing placeholder functions for logic to be detailed in later steps.

## Step 1: Define the Main Function Structure

**Goal:** Implement the basic `defineAiFunction` structure for `performComplexEditOperation` and outline its core orchestration logic using placeholders.

**Implementation:**
- Create the `performComplexEditOperation` AI function using `defineAiFunction`.
- Inside its `create` method, define the main async function that accepts `prompt` and `editor` arguments.
- **Introduce Placeholders:**
  ```typescript
  // Placeholder: Retrieves editor content
  function getEditorContent(editor: PlateEditor): string { /* TODO: Implement in Step 3 */ throw new Error("Not implemented"); }
  // Placeholder: Builds the initial prompt for the internal model
  function buildInitialPrompt(userPrompt: string, editorContent: string): GeminiChatMessage { /* TODO: Implement in Step 3 */ throw new Error("Not implemented"); }
  // Placeholder: Runs the multi-turn conversation with the internal model
  async function runInternalConversationLoop(initialPrompt: GeminiChatMessage, internalTools: AiFunction[], systemInstruction: string): Promise<LoopOutcome> { /* TODO: Implement in Step 2 */ throw new Error("Not implemented"); }
  // Placeholder: Formats the final result for the calling agent
  function formatFinalResult(loopOutcome: LoopOutcome): { success: boolean; message?: string; error?: string } { /* TODO: Implement in Step 10 */ throw new Error("Not implemented"); }
  // Placeholder: Defines the tools available to the internal model
  const internalTools: AiFunction[] = [ /* TODO: Define in Step 11 */ ];
  // Placeholder: Defines the system instructions for the internal model
  const systemInstruction: string = "/* TODO: Define in Step 11 */";
  // Placeholder type for loop outcome
  type LoopOutcome = { status: 'success' | 'failure' | 'error'; message?: string; error?: string };
  ```
- Call these placeholders in sequence: get content, build prompt, run loop, format result.

**Next Step:** Implement the structure of the `runInternalConversationLoop` function.

## Step 2: Implement the Conversation Loop Structure

**Goal:** Implement the basic structure of the `runInternalConversationLoop` function, managing turns and using placeholders for internal logic.

**Implementation:**
- Define the `runInternalConversationLoop` function signature.
- Initialize turn counter (e.g., `maxTurns = 3`).
- Initialize conversation history with the `initialPrompt`.
- Set up the `while` loop (e.g., `while (turn < maxTurns)`).
- **Introduce Placeholders within the loop:**
  ```typescript
  // Placeholder: Calls the internal Gemini model
  async function callInternalModel(history: GeminiChatMessage[], internalTools: AiFunction[], systemInstruction: string): Promise<GeminiApiResponse> { /* TODO: Implement in Step 4 */ throw new Error("Not implemented"); }
  // Placeholder: Extracts function calls from the model's response
  function extractFunctionCalls(modelResponse: GeminiApiResponse): GeminiFunctionCall[] { /* TODO: Implement in Step 5 */ throw new Error("Not implemented"); }
  // Placeholder: Executes the function calls requested by the model
  async function executeFunctionCalls(functionCalls: GeminiFunctionCall[], availableTools: AiFunction[]): Promise<FunctionCallResult[]> { /* TODO: Implement in Step 6 */ throw new Error("Not implemented"); }
  // Placeholder: Processes results to create function response messages for the model
  function prepareFunctionResponsesForModel(callResults: FunctionCallResult[]): GeminiChatMessage[] { /* TODO: Implement in Step 7 */ throw new Error("Not implemented"); }
  // Placeholder: Checks if the loop should terminate based on results and turn count
  function checkTerminationConditions(callResults: FunctionCallResult[], turn: number, maxTurns: number): boolean { /* TODO: Implement in Step 8 */ throw new Error("Not implemented"); }
  // Placeholder: Determines the final outcome of the loop
  function determineLoopOutcome(callResults: FunctionCallResult[], turn: number, maxTurns: number): LoopOutcome { /* TODO: Implement in Step 9 */ throw new Error("Not implemented"); }
  // Placeholder types
  type GeminiApiResponse = { functionCalls?: GeminiFunctionCall[]; /* ...other properties */ };
  type GeminiFunctionCall = { name: string; args: any };
  type FunctionCallResult = { id: string; name: string; success: boolean; data?: any; error?: string };
  ```
- Call these placeholders within the loop: call model, extract calls, execute calls, check termination, prepare responses, add responses to history, increment turn.
- After the loop, call `determineLoopOutcome`.

**Next Step:** Implement `getEditorContent` and `buildInitialPrompt`.

## Step 3: Implement Initial Prompt Construction

**Goal:** Implement the logic to get the current editor state and construct the initial prompt message for the internal model.

**Implementation:**
- Implement `getEditorContent`: Use `editor.getApi(MarkdownPlugin).markdown.serialize()`.
- Implement `buildInitialPrompt`: Combine the `userPrompt` and the serialized `editorContent` into a `GeminiChatMessage` (e.g., `{ role: 'user', parts: [{ text: \`User instruction: ${userPrompt}\\n\\nCurrent editor content:\\n${editorContent}\` }] }`).

**Next Step:** Implement `callInternalModel`.

## Step 4: Implement Internal Model Interaction

**Goal:** Implement the `callInternalModel` function to communicate with the internal Gemini instance.

**Implementation:**
- Use the injected `gemini` instance (ensure it's available in scope).
- Call `gemini.generateContent()` with the conversation `history`, `internalTools`, and `systemInstruction`.
- Handle potential API errors gracefully (e.g., using `tryCatchAsync`).

**Next Step:** Implement `extractFunctionCalls`.

## Step 5: Implement Model Response Processing

**Goal:** Implement `extractFunctionCalls` to safely retrieve function call requests from the model's response.

**Implementation:**
- Access the `response.functionCalls` property from the `GeminiApiResponse`.
- Handle cases where `functionCalls` might be missing or empty. Return an empty array in such cases.

**Next Step:** Implement `executeFunctionCalls`.

## Step 6: Implement Function Call Execution

**Goal:** Implement `executeFunctionCalls` to run the functions requested by the model using the provided `internalTools`.

**Implementation:**
- Iterate through the `functionCalls` array.
- For each call, find the corresponding `AiFunction` in the `availableTools` list by name.
- If found, execute the function's `create().function(...)` method with the provided arguments (`call.args`). Use `tryCatchAsync` for robust error handling.
- **Use a static placeholder ID (e.g., `"dummy-id"`)** for each result, as the specific ID is not critical here.
- Collect the results (success/failure, data/error) into an array of `FunctionCallResult`.
- If a function is not found, return an error result for that call.

**Next Step:** Implement `prepareFunctionResponsesForModel`.

## Step 7: Implement Function Result Processing

**Goal:** Implement `prepareFunctionResponsesForModel` to format the execution results into messages suitable for the next model turn.

**Implementation:**
- Iterate through the `callResults` array.
- Format each result into a `GeminiChatMessage` with `role: 'function'`.
- Include `part: { functionResponse: { name: result.name, response: { name: result.name, content: result.success ? result.data : { error: result.error } } } }`.
- Handle the specific error case: If `complete_task` was called but *other* function calls in the *same turn* failed, ensure the response for `complete_task` indicates failure (e.g., modify its `content` to include an error message like `"Couldn't complete task due to errors in other function calls."`).

**Next Step:** Implement `checkTerminationConditions`.

## Step 8: Implement Loop Termination Logic

**Goal:** Implement `checkTerminationConditions` to decide when the conversation loop should end.

**Implementation:**
- Check if the maximum turn limit (`maxTurns`) has been reached.
- Check if any `FunctionCallResult` corresponds to `complete_task`.
  - If `complete_task` was called with `success: true` AND no other calls in the same turn resulted in errors, return `true`.
  - If `complete_task` was called with `success: false`, return `true`.
- Return `false` otherwise to continue the loop.

**Next Step:** Implement `determineLoopOutcome`.

## Step 9: Implement Loop Outcome Determination

**Goal:** Implement `determineLoopOutcome` to establish the final status and message/error based on how the loop terminated.

**Implementation:**
- Examine the `callResults` from the *last* turn and the final `turn` number.
- **If `complete_task` succeeded:** Find the `complete_task` result and return `{ status: 'success', message: result.data.message }`.
- **If `complete_task` failed:** Find the `complete_task` result and return `{ status: 'failure', error: result.data.error }`.
- **If turn limit reached:** Return `{ status: 'error', error: "Complex edit failed: Maximum interaction turns reached." }`.
- **If terminated due to errors alongside `complete_task`:** Return `{ status: 'error', error: "Complex edit failed due to function call errors during completion attempt." }`. (Adjust error message as needed).

**Next Step:** Implement `formatFinalResult`.

## Step 10: Implement Final Result Formatting

**Goal:** Implement `formatFinalResult` to convert the `LoopOutcome` into the structure expected by the calling LLM agent.

**Implementation:**
- Based on `loopOutcome.status`:
  - If 'success', return `{ success: true, message: loopOutcome.message }`.
  - If 'failure', return `{ success: false, error: loopOutcome.error }`.
  - If 'error', return `{ success: false, error: loopOutcome.error }`.

**Next Step:** Define `internalTools` and `systemInstruction`.

## Step 11: Define System Prompt and Internal Tools

**Goal:** Define the specific tools and system instructions for the internal Gemini model.

**Implementation:**
- Define the `internalTools` array:
  - Include `complete_task` (imported from `src/lib/ai-functions/complete-task-ai-function.ts`).
  - Include necessary editor operations (e.g., `getEditorArtifactOperation`, `setEditorArtifactOperation`, `replaceTextOperation`, `undoOperation`, `redoOperation` - import/define these as needed).
- Define the `systemInstruction` string:
  - Clearly explain the model's role as an orchestrator for a complex edit task.
  - Describe the multi-turn process.
  - Instruct on using `complete_task` for success (`success: true`, `message`) and failure (`success: false`, `error`).
  - Emphasize calling `complete_task` *only* when the task is fully done or deemed impossible.
  - Clarify that it should *not* call `complete_task` if it needs results from other function calls in the current turn to proceed.
  - State that it *can* call multiple editor functions *and* `complete_task` in the same turn if those functions are the final steps.

**Next Step:** Refinements and Testing.

## Step 12: Refinements and Testing

**Goal:** Apply learnings, ensure code quality, and add tests.

**Implementation:**
- Review and apply points from the original "Implementation Learnings & Refinements" section (e.g., simplify signatures, check types/imports, avoid assertions, refactor for linter).
- Implement unit or integration tests for the key functions and the overall `performComplexEditOperation`.

## Original Implementation Learnings & Refinements (For Reference during Step 12)

- **Simplify `create` Function Signature:** Do **not** add explicit return type annotations (`Promise<>` or `OptionalPromise<>`) to the inner `async` function returned by `create`. Rely on TypeScript inference and the constraints of `defineAiFunction`.
- **Verify Type Structures Early:** Before accessing properties of complex types (like `LiveFunctionResponse`), confirm their structure by reading the type definition file (e.g., `src/types/multimodal-live-types.ts`). Do not rely on assumptions.
- **Confirm Import Paths:** Double-check relative paths for imports, especially when dealing with nested directories (`../` vs `../../`). Use `list_dir` if unsure.
- **Avoid Unnecessary Type Assertions:** Do not use `as any` or complex casting unless absolutely required and fully understood. Prefer adjusting types or logic.
- **Refactor for Linter Warnings:** If a linter warning (like `noUselessElse`) persists and suppression comments are ineffective, prefer a minor code refactoring that avoids the warning pattern, rather than continuing to fight the linter.
- **Focus on Core Logic:** Keep the loop and function call handling logic as straightforward as possible while meeting the core requirements.

